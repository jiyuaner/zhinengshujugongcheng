{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.datasets import cifar10\nimport tensorflow_datasets as tfds\nfrom sklearn.cluster import KMeans\nfrom sklearn.manifold import TSNE\nfrom sklearn.metrics import silhouette_score, adjusted_rand_score\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# 加载数据集\ndef load_emnist():\n    # 使用TensorFlow Datasets加载EMNIST\n    (ds_train, ds_test), ds_info = tfds.load(\n        'emnist/balanced',\n        split=['train', 'test'],\n        shuffle_files=True,\n        as_supervised=True,\n        with_info=True\n    )\n    \n    # 转换为NumPy数组\n    images, labels = [], []\n    for image, label in tfds.as_numpy(ds_train):\n        images.append(image)\n        labels.append(label)\n    \n    return np.array(images), np.array(labels)\n\n# 加载CIFAR-10\ndef load_cifar10():\n    (x_train, y_train), (_, _) = cifar10.load_data()\n    return x_train, y_train\n\n# 数据预处理\ndef preprocess(data, dataset):\n    data = data.astype('float32') / 255.\n    if dataset == 'emnist':\n        # EMNIST图像是转置的\n        data = np.rot90(data, axes=(1, 2))\n        data = np.transpose(data, (0, 2, 1, 3))\n        data = data.reshape(-1, 28 * 28)\n    elif dataset == 'cifar10':\n        data = data.reshape(-1, 32 * 32 * 3)\n    return data\n\n# 限制数据量以便快速实验\nSAMPLE_SIZE = 5000\nemnist_images, emnist_labels = load_emnist()\nemnist_data = preprocess(emnist_images[:SAMPLE_SIZE], 'emnist')\nemnist_labels = emnist_labels[:SAMPLE_SIZE]\n\ncifar_images, cifar_labels = load_cifar10()\ncifar_data = preprocess(cifar_images[:SAMPLE_SIZE], 'cifar10')\ncifar_labels = cifar_labels[:SAMPLE_SIZE].flatten()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-11T07:24:57.145664Z","iopub.execute_input":"2025-06-11T07:24:57.145986Z","iopub.status.idle":"2025-06-11T07:28:01.772406Z","shell.execute_reply.started":"2025-06-11T07:24:57.145961Z","shell.execute_reply":"2025-06-11T07:28:01.771405Z"}},"outputs":[{"name":"stdout","text":"Downloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to /root/tensorflow_datasets/emnist/balanced/3.1.0...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Dl Completed...: 0 url [00:00, ? url/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b45319e372d4cb2acf1a5aabb11d310"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Dl Size...: 0 MiB [00:00, ? MiB/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"426b2f86dc2c4d2788f4133d9eeac8c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extraction completed...: 0 file [00:00, ? file/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3562edb3ed79488ab184ce13053f13aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extraction completed...: 0 file [00:00, ? file/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d702146737a94ca38a6d520d414f30fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating splits...:   0%|          | 0/2 [00:00<?, ? splits/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train examples...: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"I0000 00:00:1749626710.507153      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Shuffling /root/tensorflow_datasets/emnist/balanced/incomplete.SD1RGY_3.1.0/emnist-train.tfrecord*...:   0%|  …","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test examples...: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Shuffling /root/tensorflow_datasets/emnist/balanced/incomplete.SD1RGY_3.1.0/emnist-test.tfrecord*...:   0%|   …","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset emnist downloaded and prepared to /root/tensorflow_datasets/emnist/balanced/3.1.0. Subsequent calls will reuse this data.\nDownloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# 构建自编码器\ndef build_ae(input_dim, encoding_dim=64):\n    input_layer = tf.keras.Input(shape=(input_dim,))\n    \n    # 编码器\n    encoded = tf.keras.layers.Dense(256, activation='relu')(input_layer)\n    encoded = tf.keras.layers.Dense(128, activation='relu')(encoded)\n    encoded = tf.keras.layers.Dense(encoding_dim, activation='relu')(encoded)\n    \n    # 解码器\n    decoded = tf.keras.layers.Dense(128, activation='relu')(encoded)\n    decoded = tf.keras.layers.Dense(256, activation='relu')(decoded)\n    decoded = tf.keras.layers.Dense(input_dim, activation='sigmoid')(decoded)\n    \n    autoencoder = tf.keras.Model(input_layer, decoded)\n    encoder = tf.keras.Model(input_layer, encoded)\n    \n    autoencoder.compile(optimizer='adam', loss='mse')\n    return autoencoder, encoder","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T07:28:07.973144Z","iopub.execute_input":"2025-06-11T07:28:07.973495Z","iopub.status.idle":"2025-06-11T07:28:07.979847Z","shell.execute_reply.started":"2025-06-11T07:28:07.973474Z","shell.execute_reply":"2025-06-11T07:28:07.979095Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def evaluate_clustering(data, labels, n_clusters, use_ae=True, encoding_dim=64, verbose=0):\n    # 处理不同数据集\n    dataset = 'emnist' if data.shape[1] == 28 * 28 else 'cifar10'\n    \n    if use_ae:\n        # 训练自编码器\n        autoencoder, encoder = build_ae(data.shape[1], encoding_dim)\n        autoencoder.fit(\n            data, data,\n            epochs=20,\n            batch_size=256,\n            verbose=verbose,\n            callbacks=[\n                tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n            ]\n        )\n        features = encoder.predict(data, verbose=verbose)\n    else:\n        # 原始特征PCA降维\n        pca = PCA(n_components=encoding_dim)\n        features = pca.fit_transform(data)\n    \n    # K-means聚类\n    kmeans = KMeans(n_clusters=n_clusters, n_init=10, random_state=42)\n    clusters = kmeans.fit_predict(features)\n    \n    # 评估指标\n    sil_score = silhouette_score(features, clusters)\n    ari_score = adjusted_rand_score(labels, clusters)\n    \n    return sil_score, ari_score, features, clusters, kmeans","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T07:28:11.274759Z","iopub.execute_input":"2025-06-11T07:28:11.275066Z","iopub.status.idle":"2025-06-11T07:28:11.282116Z","shell.execute_reply.started":"2025-06-11T07:28:11.275044Z","shell.execute_reply":"2025-06-11T07:28:11.281120Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def find_optimal_dim(data, labels, n_clusters, dataset_name):\n    dims = [16, 32, 64, 128, 256]\n    results = {'ae': {'sil': [], 'ari': []}, 'raw': {'sil': [], 'ari': []}}\n    \n    for dim in dims:\n        # 使用AE\n        sil_ae, ari_ae, _, _, _ = evaluate_clustering(\n            data, labels, n_clusters, True, dim, verbose=0\n        )\n        # 原始特征\n        sil_raw, ari_raw, _, _, _ = evaluate_clustering(\n            data, labels, n_clusters, False, dim, verbose=0\n        )\n        \n        results['ae']['sil'].append(sil_ae)\n        results['ae']['ari'].append(ari_ae)\n        results['raw']['sil'].append(sil_raw)\n        results['raw']['ari'].append(ari_raw)\n        \n        print(f\"{dataset_name} Dim={dim}: AE(sil={sil_ae:.4f}, ari={ari_ae:.4f}) | Raw(sil={sil_raw:.4f}, ari={ari_raw:.4f})\")\n    \n    # 可视化结果\n    plt.figure(figsize=(12, 5))\n    plt.subplot(1, 2, 1)\n    plt.plot(dims, results['ae']['sil'], 'o-', label='AE')\n    plt.plot(dims, results['raw']['sil'], 'o-', label='Raw')\n    plt.title(f'{dataset_name} Silhouette Score')\n    plt.xlabel('Dimension')\n    plt.ylabel('Score')\n    plt.legend()\n    plt.grid(True)\n    \n    plt.subplot(1, 2, 2)\n    plt.plot(dims, results['ae']['ari'], 'o-', label='AE')\n    plt.plot(dims, results['raw']['ari'], 'o-', label='Raw')\n    plt.title(f'{dataset_name} ARI Score')\n    plt.xlabel('Dimension')\n    plt.ylabel('Score')\n    plt.legend()\n    plt.grid(True)\n    plt.tight_layout()\n    plt.savefig(f'{dataset_name}_dim_optim.png')\n    plt.close()\n    \n    return results\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:05:24.746551Z","iopub.execute_input":"2025-06-11T08:05:24.747077Z","iopub.status.idle":"2025-06-11T08:05:24.756178Z","shell.execute_reply.started":"2025-06-11T08:05:24.747053Z","shell.execute_reply":"2025-06-11T08:05:24.755439Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# 首先需要重新运行维度优化并保存结果\n\n# 执行优化\nprint(\"\\n==== EMNIST Dimension Optimization ====\")\ndims = [16, 32, 64, 128, 256]\nresults_emnist = {'ae': {'sil': [], 'ari': []}, 'raw': {'sil': [], 'ari': []}}\n\nfor dim in dims:\n    sil_ae, ari_ae, _, _, _ = evaluate_clustering(\n        emnist_data, emnist_labels, 47, True, dim, verbose=0\n    )\n    sil_raw, ari_raw, _, _, _ = evaluate_clustering(\n        emnist_data, emnist_labels, 47, False, dim, verbose=0\n    )\n    \n    results_emnist['ae']['sil'].append(sil_ae)\n    results_emnist['ae']['ari'].append(ari_ae)\n    results_emnist['raw']['sil'].append(sil_raw)\n    results_emnist['raw']['ari'].append(ari_raw)\n    \n    print(f\"EMNIST Dim={dim}: AE(sil={sil_ae:.4f}, ari={ari_ae:.4f}) | Raw(sil={sil_raw:.4f}, ari={ari_raw:.4f})\")\n\n# CIFAR10维度优化\nprint(\"\\n==== CIFAR10 Dimension Optimization ====\")\nresults_cifar = {'ae': {'sil': [], 'ari': []}, 'raw': {'sil': [], 'ari': []}}\n\nfor dim in dims:\n    sil_ae, ari_ae, _, _, _ = evaluate_clustering(\n        cifar_data, cifar_labels, 10, True, dim, verbose=0\n    )\n    sil_raw, ari_raw, _, _, _ = evaluate_clustering(\n        cifar_data, cifar_labels, 10, False, dim, verbose=0\n    )\n    \n    results_cifar['ae']['sil'].append(sil_ae)\n    results_cifar['ae']['ari'].append(ari_ae)\n    results_cifar['raw']['sil'].append(sil_raw)\n    results_cifar['raw']['ari'].append(ari_raw)\n    \n    print(f\"CIFAR10 Dim={dim}: AE(sil={sil_ae:.4f}, ari={ari_ae:.4f}) | Raw(sil={sil_raw:.4f}, ari={ari_raw:.4f})\")\n\n# 找出最佳维度\nbest_dim_emnist = dims[np.argmax(results_emnist['ae']['ari'])]\nbest_dim_cifar = dims[np.argmax(results_cifar['ae']['ari'])]\n\n# 使用最优维度进行聚类和可视化\nprint(f\"\\n==== EMNIST Analysis with AE (Dim={best_dim_emnist}) ====\")\nsil_ae, ari_ae, feats_emnist, clusters_emnist, _ = evaluate_clustering(\n    emnist_data, emnist_labels, 47, True, best_dim_emnist, verbose=1\n)\nemnist_errors = visualize_comparison(\n    emnist_data, feats_emnist, emnist_labels, clusters_emnist, 'EMNIST'\n)\n\nprint(f\"\\n==== CIFAR10 Analysis with AE (Dim={best_dim_cifar}) ====\")\nsil_ae_cifar, ari_ae_cifar, feats_cifar, clusters_cifar, _ = evaluate_clustering(\n    cifar_data, cifar_labels, 10, True, best_dim_cifar, verbose=1\n)\ncifar_errors = visualize_comparison(\n    cifar_data, feats_cifar, cifar_labels, clusters_cifar, 'CIFAR10'\n)\n\n# 打印结论\nprint(\"\\n==== Analysis Conclusion ====\")\nprint(\"EMNIST最易混淆的字符对:\")\nfor true_label, false_label in emnist_errors.items():\n    print(f\"  类别 {true_label} 经常被误分类为 {false_label}\")\n\nprint(\"\\nCIFAR10最易混淆的类别对:\")\nfor true_label, false_label in cifar_errors.items():\n    print(f\"  类别 {true_label} 经常被误分类为 {false_label}\")\n\n# 性能比较 - 使用保存的结果进行公平比较\nbest_idx_emnist = dims.index(best_dim_emnist)\nbest_idx_cifar = dims.index(best_dim_cifar)\n\nprint(\"\\n==== Performance Summary ====\")\nprint(\"EMNIST:\")\nprint(f\"  AE特征轮廓系数: {results_emnist['ae']['sil'][best_idx_emnist]:.4f}, 调整兰德指数: {results_emnist['ae']['ari'][best_idx_emnist]:.4f}\")\nprint(f\"  原始特征轮廓系数: {results_emnist['raw']['sil'][best_idx_emnist]:.4f}, 调整兰德指数: {results_emnist['raw']['ari'][best_idx_emnist]:.4f}\")\n\nprint(\"\\nCIFAR10:\")\nprint(f\"  AE特征轮廓系数: {results_cifar['ae']['sil'][best_idx_cifar]:.4f}, 调整兰德指数: {results_cifar['ae']['ari'][best_idx_cifar]:.4f}\")\nprint(f\"  原始特征轮廓系数: {results_cifar['raw']['sil'][best_idx_cifar]:.4f}, 调整兰德指数: {results_cifar['raw']['ari'][best_idx_cifar]:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T07:37:43.182234Z","iopub.execute_input":"2025-06-11T07:37:43.183241Z","iopub.status.idle":"2025-06-11T07:40:58.696539Z","shell.execute_reply.started":"2025-06-11T07:37:43.183180Z","shell.execute_reply":"2025-06-11T07:40:58.695644Z"}},"outputs":[{"name":"stdout","text":"\n==== EMNIST Dimension Optimization ====\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n  current = self.get_monitor_value(logs)\n","output_type":"stream"},{"name":"stdout","text":"EMNIST Dim=16: AE(sil=0.1043, ari=0.0986) | Raw(sil=0.0913, ari=0.1616)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n  current = self.get_monitor_value(logs)\n","output_type":"stream"},{"name":"stdout","text":"EMNIST Dim=32: AE(sil=0.0852, ari=0.1058) | Raw(sil=0.0709, ari=0.1702)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n  current = self.get_monitor_value(logs)\n","output_type":"stream"},{"name":"stdout","text":"EMNIST Dim=64: AE(sil=0.0769, ari=0.1017) | Raw(sil=0.0572, ari=0.1591)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n  current = self.get_monitor_value(logs)\n","output_type":"stream"},{"name":"stdout","text":"EMNIST Dim=128: AE(sil=0.0726, ari=0.1175) | Raw(sil=0.0452, ari=0.1583)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n  current = self.get_monitor_value(logs)\n","output_type":"stream"},{"name":"stdout","text":"EMNIST Dim=256: AE(sil=0.0759, ari=0.1310) | Raw(sil=0.0458, ari=0.1638)\n\n==== CIFAR10 Dimension Optimization ====\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n  current = self.get_monitor_value(logs)\n","output_type":"stream"},{"name":"stdout","text":"CIFAR10 Dim=16: AE(sil=0.1171, ari=0.0323) | Raw(sil=0.0991, ari=0.0474)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n  current = self.get_monitor_value(logs)\n","output_type":"stream"},{"name":"stdout","text":"CIFAR10 Dim=32: AE(sil=0.1030, ari=0.0362) | Raw(sil=0.0739, ari=0.0451)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n  current = self.get_monitor_value(logs)\n","output_type":"stream"},{"name":"stdout","text":"CIFAR10 Dim=64: AE(sil=0.1018, ari=0.0441) | Raw(sil=0.0718, ari=0.0470)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n  current = self.get_monitor_value(logs)\n","output_type":"stream"},{"name":"stdout","text":"CIFAR10 Dim=128: AE(sil=0.0861, ari=0.0438) | Raw(sil=0.0658, ari=0.0482)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n  current = self.get_monitor_value(logs)\n","output_type":"stream"},{"name":"stdout","text":"CIFAR10 Dim=256: AE(sil=0.0900, ari=0.0489) | Raw(sil=0.0616, ari=0.0474)\n\n==== EMNIST Analysis with AE (Dim=256) ====\nEpoch 1/20\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.1701\nEpoch 2/20\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0903\nEpoch 3/20\n\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0821 ","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n  current = self.get_monitor_value(logs)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0817\nEpoch 4/20\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0697\nEpoch 5/20\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0568\nEpoch 6/20\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0473\nEpoch 7/20\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0415\nEpoch 8/20\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0380\nEpoch 9/20\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0339\nEpoch 10/20\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0318\nEpoch 11/20\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0297\nEpoch 12/20\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0279\nEpoch 13/20\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0269\nEpoch 14/20\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0248\nEpoch 15/20\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0233\nEpoch 16/20\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0227\nEpoch 17/20\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0218\nEpoch 18/20\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0211\nEpoch 19/20\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0201\nEpoch 20/20\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0198\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n\n==== CIFAR10 Analysis with AE (Dim=256) ====\nEpoch 1/20\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0631\nEpoch 2/20\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0512\nEpoch 3/20\n\u001b[1m 1/20\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0430","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n  current = self.get_monitor_value(logs)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0431\nEpoch 4/20\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0413\nEpoch 5/20\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0383\nEpoch 6/20\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0365\nEpoch 7/20\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0351\nEpoch 8/20\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0305\nEpoch 9/20\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0338\nEpoch 10/20\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0280\nEpoch 11/20\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0263\nEpoch 12/20\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0258\nEpoch 13/20\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0237\nEpoch 14/20\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0234\nEpoch 15/20\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0225\nEpoch 16/20\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0242\nEpoch 17/20\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0221\nEpoch 18/20\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0219\nEpoch 19/20\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0214\nEpoch 20/20\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0209\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n\n==== Analysis Conclusion ====\nEMNIST最易混淆的字符对:\n  类别 0 经常被误分类为 24\n  类别 1 经常被误分类为 18\n  类别 2 经常被误分类为 26\n  类别 3 经常被误分类为 11\n  类别 4 经常被误分类为 41\n  类别 5 经常被误分类为 14\n  类别 6 经常被误分类为 37\n  类别 7 经常被误分类为 19\n  类别 8 经常被误分类为 39\n  类别 9 经常被误分类为 44\n  类别 10 经常被误分类为 27\n  类别 11 经常被误分类为 3\n  类别 12 经常被误分类为 39\n  类别 13 经常被误分类为 11\n  类别 14 经常被误分类为 5\n  类别 15 经常被误分类为 40\n  类别 16 经常被误分类为 5\n  类别 17 经常被误分类为 23\n  类别 18 经常被误分类为 1\n  类别 19 经常被误分类为 41\n  类别 20 经常被误分类为 27\n  类别 21 经常被误分类为 1\n  类别 22 经常被误分类为 43\n  类别 23 经常被误分类为 17\n  类别 24 经常被误分类为 0\n  类别 25 经常被误分类为 15\n  类别 26 经常被误分类为 2\n  类别 27 经常被误分类为 20\n  类别 28 经常被误分类为 5\n  类别 29 经常被误分类为 45\n  类别 30 经常被误分类为 31\n  类别 31 经常被误分类为 4\n  类别 32 经常被误分类为 23\n  类别 33 经常被误分类为 20\n  类别 34 经常被误分类为 1\n  类别 35 经常被误分类为 2\n  类别 36 经常被误分类为 35\n  类别 37 经常被误分类为 42\n  类别 38 经常被误分类为 8\n  类别 39 经常被误分类为 35\n  类别 40 经常被误分类为 15\n  类别 41 经常被误分类为 4\n  类别 42 经常被误分类为 37\n  类别 43 经常被误分类为 10\n  类别 44 经常被误分类为 9\n  类别 45 经常被误分类为 29\n  类别 46 经常被误分类为 45\n\nCIFAR10最易混淆的类别对:\n  类别 0 经常被误分类为 8\n  类别 1 经常被误分类为 8\n  类别 2 经常被误分类为 6\n  类别 3 经常被误分类为 6\n  类别 4 经常被误分类为 6\n  类别 5 经常被误分类为 3\n  类别 6 经常被误分类为 4\n  类别 7 经常被误分类为 4\n  类别 8 经常被误分类为 9\n  类别 9 经常被误分类为 7\n\n==== Performance Summary ====\nEMNIST:\n  AE特征轮廓系数: 0.0759, 调整兰德指数: 0.1310\n  原始特征轮廓系数: 0.0458, 调整兰德指数: 0.1638\n\nCIFAR10:\n  AE特征轮廓系数: 0.0900, 调整兰德指数: 0.0489\n  原始特征轮廓系数: 0.0616, 调整兰德指数: 0.0474\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}