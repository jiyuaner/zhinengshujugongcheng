{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11302896,"sourceType":"datasetVersion","datasetId":7068713}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers accelerate sentence-transformers faiss-cpu\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-08T05:28:36.893643Z","iopub.execute_input":"2025-04-08T05:28:36.893923Z","iopub.status.idle":"2025-04-08T05:28:43.028536Z","shell.execute_reply.started":"2025-04-08T05:28:36.893867Z","shell.execute_reply":"2025-04-08T05:28:43.027506Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.2.1)\nRequirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.3.1)\nCollecting faiss-cpu\n  Downloading faiss_cpu-1.10.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\nRequirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.0.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.12.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading faiss_cpu-1.10.0-cp310-cp310-manylinux_2_28_x86_64.whl (30.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0mm\n\u001b[?25hInstalling collected packages: faiss-cpu\nSuccessfully installed faiss-cpu-1.10.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nimport faiss\nimport numpy as np\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nimport torch\n\n# 加载本地 DeepSeek 模型\nmodel_name = \"deepseek-ai/deepseek-llm-7b-chat\"\ntokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\nllm = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    device_map=\"auto\",\n    torch_dtype=torch.float16,\n    trust_remote_code=True\n)\nllm.eval()\n\n# 知识库内容\nknowledge_texts = [\n    \"数据存储是指以一定结构保存数据的方式，包括关系型数据库和非关系型数据库。\",\n    \"信息抽取是从非结构化或半结构化数据中提取结构化信息的过程。\",\n    \"向量数据库使用向量表示文本，可用于高效的语义搜索。\",\n    \"知识问答系统分为基于检索的问答和基于生成的问答。\",\n    \"知识图谱是一种语义网络，表示实体及其之间的关系。\"\n]\n\n# 从PPT提取的txt文件（例如：你用python-pptx或其他工具提取保存的）\nppt_file_path = '/kaggle/input/ppttxt/ppt.txt'\n\n# 加载并分句（可按段落或换行分割）\nwith open(ppt_file_path, 'r', encoding='utf-8') as f:\n    ppt_content = f.read()\n\n# 分割成知识段（你可以根据自己的格式调整，以下按“换行”分段）\nppt_knowledge_list = [line.strip() for line in ppt_content.split('\\n') if line.strip()]\n\n# 合并\nknowledge_texts.extend(ppt_knowledge_list)\n\n# 文本向量化 + FAISS 向量搜索\nembedder = SentenceTransformer(\"shibing624/text2vec-base-chinese\")  # 中文效果更好\ndoc_embeddings = embedder.encode(knowledge_texts)\ndimension = doc_embeddings.shape[1]\nindex = faiss.IndexFlatL2(dimension)\nindex.add(np.array(doc_embeddings))\n\n# 问答函数\ndef answer_question_with_deepseek(question, top_k=2, max_new_tokens=200):\n    # 检索相关知识\n    q_embedding = embedder.encode([question])\n    distances, indices = index.search(np.array(q_embedding), top_k)\n    retrieved = [knowledge_texts[i] for i in indices[0]]\n\n    # 构造 Prompt\n    context = \"\\n\".join(retrieved)\n    prompt = f\"\"\"你是一位智能问答助手，请根据以下知识内容回答用户的问题。\n知识内容：\n{context}\n\n用户问题：{question}\n你的回答：\"\"\"\n\n    # 模型推理\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(llm.device)\n    with torch.no_grad():\n        outputs = llm.generate(\n            **inputs,\n            max_new_tokens=max_new_tokens,\n            do_sample=True,\n            temperature=0.7,\n            top_p=0.9,\n            repetition_penalty=1.1,\n        )\n    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n    # 去除prompt前缀，只返回回答部分\n    answer = response.split(\"你的回答：\")[-1].strip()\n    return answer\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T02:51:49.438549Z","iopub.execute_input":"2025-04-07T02:51:49.438829Z","iopub.status.idle":"2025-04-07T02:53:33.083022Z","shell.execute_reply.started":"2025-04-07T02:51:49.438807Z","shell.execute_reply":"2025-04-07T02:53:33.082226Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.28k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07ea8259dcbc462e918cd055d8a14c1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/4.61M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d9b5b0cd3dc41c99eb9cd5e491bb493"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/594 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba446651cb04490dbcd9a9c523599f4c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin.index.json:   0%|          | 0.00/22.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac43bffc5dcd44169f4d78aafdda49c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24834d7d8ff045428ca2e59a59e4a9c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1e1e2dd2bd741c7a72c110246c24b89"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00002-of-00002.bin:   0%|          | 0.00/3.85G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2be512fc81cd463485dd520147143477"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0d44172faf240ca82c94ee71a3fdf12"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de06d4a998a14458beb27b9aebde0ded"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/230 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52bd3d3a5bc94fbabdf8f64622bcc5d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/13.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a31042675efb4df0ad2c92b104a46925"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/54.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73e2dbdab3c141999f7fa311b59b35aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/856 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0188e3881bdb449b9e8ae760285eab57"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/409M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5536170016e54b3390802b886e69c6d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/319 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dae673957bf7410babe7e67182b3f772"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/110k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"369338e45ceb4a599580d3c697b5a11b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f68d04854a014b3ebb5a82d55bfdb233"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/74.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ed4aa7048974b06ac7efe4cb6523453"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65d557d934454e618b04da55c277d74b"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"question = \"向量数据库的作用是什么？\"\nprint(\"问：\", question)\nprint(\"答：\", answer_question_with_deepseek(question))\nquestion = \"什么是信息抽取？\"\nprint(\"问：\", question)\nprint(\"答：\", answer_question_with_deepseek(question))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T02:53:36.336987Z","iopub.execute_input":"2025-04-07T02:53:36.337716Z","iopub.status.idle":"2025-04-07T02:53:40.334330Z","shell.execute_reply.started":"2025-04-07T02:53:36.337681Z","shell.execute_reply":"2025-04-07T02:53:40.333487Z"}},"outputs":[{"name":"stdout","text":"问： 向量数据库的作用是什么？\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e40c8a214862477fb81ef4288f07ccf2"}},"metadata":{}},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:100001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"答： 向量数据库是一种使用向量来存储和检索数据的数据库类型，主要应用于需要高效处理大量数据的场景中。它的作用包括但不限于语义搜索、推荐系统等领域的应用。\n问： 什么是信息抽取？\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a33ea2f40da4524a8eff3dacfe610fc"}},"metadata":{}},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:100001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"答： 信息抽取是指从文本等非结构化或半结构化数据中自动提取出结构化信息的处理过程。\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nimport faiss\nimport numpy as np\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nimport torch\n# 替换 DeepSeek 模型为 chatglm3\nmodel_name = \"THUDM/chatglm3-6b\"\ntokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\nllm = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    trust_remote_code=True,\n    torch_dtype=torch.float16,\n    device_map=\"auto\"\n)\nllm.eval()\n\n\n# 知识库内容\nknowledge_texts = [\n    \"数据存储是指以一定结构保存数据的方式，包括关系型数据库和非关系型数据库。\",\n    \"信息抽取是从非结构化或半结构化数据中提取结构化信息的过程。\",\n    \"向量数据库使用向量表示文本，可用于高效的语义搜索。\",\n    \"知识问答系统分为基于检索的问答和基于生成的问答。\",\n    \"知识图谱是一种语义网络，表示实体及其之间的关系。\"\n]\n\nppt_file_path = '/kaggle/input/ppttxt/ppt.txt'\n\n# 加载并分句（可按段落或换行分割）\nwith open(ppt_file_path, 'r', encoding='utf-8') as f:\n    ppt_content = f.read()\n\n# 分割成知识段（你可以根据自己的格式调整，以下按“换行”分段）\nppt_knowledge_list = [line.strip() for line in ppt_content.split('\\n') if line.strip()]\n\n# 合并\nknowledge_texts.extend(ppt_knowledge_list)\n\n# 文本向量化 + FAISS 向量搜索\nembedder = SentenceTransformer(\"shibing624/text2vec-base-chinese\")  # 中文效果更好\ndoc_embeddings = embedder.encode(knowledge_texts)\ndimension = doc_embeddings.shape[1]\nindex = faiss.IndexFlatL2(dimension)\nindex.add(np.array(doc_embeddings))\n\n# 问答函数\ndef answer_question_with_deepseek(question, top_k=2, max_new_tokens=200):\n    # 检索相关知识\n    q_embedding = embedder.encode([question])\n    distances, indices = index.search(np.array(q_embedding), top_k)\n    retrieved = [knowledge_texts[i] for i in indices[0]]\n\n    # 构造 Prompt\n    context = \"\\n\".join(retrieved)\n    prompt = f\"\"\"你是一位智能问答助手，请根据以下知识内容回答用户的问题。\n知识内容：\n{context}\n\n用户问题：{question}\n你的回答：\"\"\"\n\n    # 模型推理\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(llm.device)\n    with torch.no_grad():\n        outputs = llm.generate(\n            **inputs,\n            max_new_tokens=max_new_tokens,\n            do_sample=True,\n            temperature=0.7,\n            top_p=0.9,\n            repetition_penalty=1.1,\n        )\n    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n    # 去除prompt前缀，只返回回答部分\n    answer = response.split(\"你的回答：\")[-1].strip()\n    return answer\nquestion = \"向量数据库的作用是什么？\"\nprint(\"问：\", question)\nprint(\"答：\", answer_question_with_deepseek(question))\nquestion = \"什么是信息抽取？\"\nprint(\"问：\", question)\nprint(\"答：\", answer_question_with_deepseek(question))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T05:12:22.280175Z","iopub.execute_input":"2025-04-08T05:12:22.280601Z","iopub.status.idle":"2025-04-08T05:14:07.947473Z","shell.execute_reply.started":"2025-04-08T05:12:22.280562Z","shell.execute_reply":"2025-04-08T05:14:07.946592Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc47827abfb74d62ab15be72f232c357"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenization_chatglm.py:   0%|          | 0.00/13.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6253223a73fc46d39f166300d6414fe0"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm3-6b:\n- tokenization_chatglm.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/1.02M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b258548824864f56b01702c9e63f2eb4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/3.00 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fbe09cec34e47198d5043492c7ffe7a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.32k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"882d7a8c18a9442ab331190416eb1a77"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_chatglm.py:   0%|          | 0.00/2.33k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b88ad003d3e452cabb8e3f5de3e810f"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm3-6b:\n- configuration_chatglm.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_chatglm.py:   0%|          | 0.00/56.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42a8d393363b43de95dfc31795764186"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"quantization.py:   0%|          | 0.00/14.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7ebee5ab98c4f48b831d3bf2570583b"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm3-6b:\n- quantization.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\nA new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm3-6b:\n- modeling_chatglm.py\n- quantization.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/21.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fdd16e8116741d69a450dd836280422"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2c65018c8a740a69dfbea7d23a0a774"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00007.safetensors:   0%|          | 0.00/1.83G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ff307e0e81d4620809fbead5b6269cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00007.safetensors:   0%|          | 0.00/1.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb16a59d328c483b94fc34bb548e652e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00007.safetensors:   0%|          | 0.00/1.93G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ef0ba687d534dafb10681c92151efbf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00007.safetensors:   0%|          | 0.00/1.82G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf15feaa9bec402f951f7341289de776"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00005-of-00007.safetensors:   0%|          | 0.00/1.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65bf19a718b7479198adb6345a8f24c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00006-of-00007.safetensors:   0%|          | 0.00/1.93G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21e581b7c04d473d9a3a8615357ca97c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00007-of-00007.safetensors:   0%|          | 0.00/1.05G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14c9abe63fae4888bd8f2a25764608dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"903c7bb90c074b48bb21bb0fb414b4fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/230 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f0ba5211cf842928c015c81fcae7439"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/13.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"056486cdfa7a41d394033d1b215792f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/54.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"768230dc215e48b2be3d20bce175fd5c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/856 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2d80ff4eb94412aafcc3454f87df98d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/409M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d960d87fded450fb433627938c1dcf0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/319 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33bf63e088104569a564461bb2ddbe19"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/110k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ecf8be8a8d945bc8c72011ea8247ff8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b327c2ed7aaa4351860b21bb15ef26e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/74.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52deb5af1e114f43a5e48b8c173907d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1cef961b70b549aaba81304a2b855382"}},"metadata":{}},{"name":"stdout","text":"问： 向量数据库的作用是什么？\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d69e70d526544f4c8c8dd4de66e4dc4d"}},"metadata":{}},{"name":"stdout","text":"答： 向量数据库的作用是使用向量表示文本，以便进行高效的语义搜索。通过将文本转换为向量形式，可以向数据库中快速检索和匹配相关内容。这种方法可以提高查询效率，降低系统延迟，并且有助于实现更精准的搜索结果。向量数据库通常用于需要处理大量文本数据的应用程序，例如自然语言处理、信息检索和文本分类等。\n问： 什么是信息抽取？\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"011b05c7633a4e28b2584d686b6d03fc"}},"metadata":{}},{"name":"stdout","text":"答： 信息抽取是从非结构化或半结构化数据中提取结构化信息的过程。它是一种文本处理技术，用于从原始文本中识别和提取出有用的信息，以便进行进一步的分析和利用。信息抽取广泛应用于各种领域，如自然语言处理、数据库抽取、数据挖掘等。\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nimport faiss\nimport numpy as np\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nimport torch\n\nmodel_name = \"baichuan-inc/Baichuan2-7B-Chat\"\ntokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\nllm = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n    trust_remote_code=True\n)\nllm.eval()\n\n\n# 知识库内容\nknowledge_texts = [\n    \"数据存储是指以一定结构保存数据的方式，包括关系型数据库和非关系型数据库。\",\n    \"信息抽取是从非结构化或半结构化数据中提取结构化信息的过程。\",\n    \"向量数据库使用向量表示文本，可用于高效的语义搜索。\",\n    \"知识问答系统分为基于检索的问答和基于生成的问答。\",\n    \"知识图谱是一种语义网络，表示实体及其之间的关系。\"\n]\n\nppt_file_path = '/kaggle/input/ppttxt/ppt.txt'\n\n# 加载并分句（可按段落或换行分割）\nwith open(ppt_file_path, 'r', encoding='utf-8') as f:\n    ppt_content = f.read()\n\n# 分割成知识段（你可以根据自己的格式调整，以下按“换行”分段）\nppt_knowledge_list = [line.strip() for line in ppt_content.split('\\n') if line.strip()]\n\n# 合并\nknowledge_texts.extend(ppt_knowledge_list)\n\n# 文本向量化 + FAISS 向量搜索\nembedder = SentenceTransformer(\"shibing624/text2vec-base-chinese\")  # 中文效果更好\ndoc_embeddings = embedder.encode(knowledge_texts)\ndimension = doc_embeddings.shape[1]\nindex = faiss.IndexFlatL2(dimension)\nindex.add(np.array(doc_embeddings))\n\n# 问答函数\ndef answer_question_with_deepseek(question, top_k=2, max_new_tokens=200):\n    # 检索相关知识\n    q_embedding = embedder.encode([question])\n    distances, indices = index.search(np.array(q_embedding), top_k)\n    retrieved = [knowledge_texts[i] for i in indices[0]]\n\n    # 构造 Prompt\n    context = \"\\n\".join(retrieved)\n    prompt = f\"\"\"你是一位智能问答助手，请根据以下知识内容回答用户的问题。\n知识内容：\n{context}\n\n用户问题：{question}\n你的回答：\"\"\"\n\n    # 模型推理\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(llm.device)\n    with torch.no_grad():\n        outputs = llm.generate(\n            **inputs,\n            max_new_tokens=max_new_tokens,\n            do_sample=True,\n            temperature=0.7,\n            top_p=0.9,\n            repetition_penalty=1.1,\n        )\n    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n    # 去除prompt前缀，只返回回答部分\n    answer = response.split(\"你的回答：\")[-1].strip()\n    return answer\nquestion = \"向量数据库的作用是什么？\"\nprint(\"问：\", question)\nprint(\"答：\", answer_question_with_deepseek(question))\nquestion = \"什么是信息抽取？\"\nprint(\"问：\", question)\nprint(\"答：\", answer_question_with_deepseek(question))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T05:18:45.230315Z","iopub.execute_input":"2025-04-08T05:18:45.230639Z","iopub.status.idle":"2025-04-08T05:20:55.089495Z","shell.execute_reply.started":"2025-04-08T05:18:45.230615Z","shell.execute_reply":"2025-04-08T05:20:55.088375Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"generation_utils.py:   0%|          | 0.00/2.97k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a9077155f4e4db6b13defca3283062d"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/baichuan-inc/Baichuan2-7B-Chat:\n- generation_utils.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\nA new version of the following files was downloaded from https://huggingface.co/baichuan-inc/Baichuan2-7B-Chat:\n- quantizer.py\n- generation_utils.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/15.0G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a8a92ba554c437487ceeb8b811bc509"}},"metadata":{}},{"name":"stderr","text":"Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/15.0G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d195180533f2410a9a0b7df44c0f2654"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/285 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7e317537aca4f24aa4ad50502a6e040"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/230 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6d1aa7e34234e1cbd2dd25126e7e17d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/13.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c521e12ddb44e5091a4c09953ab0db9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/54.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1347e4fbc2744d0b96014f3f0d8d2e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/856 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6058033c07248e2b63bfc776a18924f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/409M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78a992ea6676413cb0052907539f88c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/319 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a37c5929b684680b014bad0384c311e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/110k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e00dda8533f442c4bf2f9ffed7fe5a99"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6575e05f4ff4fc98536e9c70e362c77"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/74.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9dfeaea789c64657bb1c5f6794b0f2ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ff92711d3814623b5d784f3e073a4cf"}},"metadata":{}},{"name":"stdout","text":"问： 向量数据库的作用是什么？\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d6de553a4f743d98d822bb69bc04c52"}},"metadata":{}},{"name":"stderr","text":"/usr/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n  self.gen = func(*args, **kwds)\n","output_type":"stream"},{"name":"stdout","text":"答： 向量数据库是一种用于存储和管理大量文本数据的数据库技术，它使用向量表示文本，从而实现高效、准确的语义搜索。这种数据库可以有效地处理大量的非结构化数据，例如社交媒体帖子、评论和新闻文章等。通过将文本转换为数值向量，向量数据库能够更好地理解和比较这些数据，从而使搜索更加精确和相关。\n问： 什么是信息抽取？\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8caa06a1f2624cd5a252ec293d0b591a"}},"metadata":{}},{"name":"stdout","text":"答： 信息抽取（Information Extraction）是从非结构化或半结构化数据中提取结构化信息的过程。这个过程可以帮助我们从大量的文本、数据库或其他数据源中快速找到和提取有用的信息。通过使用自然语言处理（NLP）技术和机器学习算法，信息抽取可以将原始数据转化为结构化的表格和数据集，从而为数据分析、挖掘和可视化提供基础。\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nimport faiss\nimport numpy as np\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nimport torch\n\nmodel_name = \"Qwen/Qwen-7B-Chat\"\ntokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\nllm = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n    trust_remote_code=True\n)\nllm.eval()\n\n\n# 知识库内容\nknowledge_texts = [\n    \"数据存储是指以一定结构保存数据的方式，包括关系型数据库和非关系型数据库。\",\n    \"信息抽取是从非结构化或半结构化数据中提取结构化信息的过程。\",\n    \"向量数据库使用向量表示文本，可用于高效的语义搜索。\",\n    \"知识问答系统分为基于检索的问答和基于生成的问答。\",\n    \"知识图谱是一种语义网络，表示实体及其之间的关系。\"\n]\n\nppt_file_path = '/kaggle/input/ppttxt/ppt.txt'\n\n# 加载并分句（可按段落或换行分割）\nwith open(ppt_file_path, 'r', encoding='utf-8') as f:\n    ppt_content = f.read()\n\n# 分割成知识段（你可以根据自己的格式调整，以下按“换行”分段）\nppt_knowledge_list = [line.strip() for line in ppt_content.split('\\n') if line.strip()]\n\n# 合并\nknowledge_texts.extend(ppt_knowledge_list)\n\n# 文本向量化 + FAISS 向量搜索\nembedder = SentenceTransformer(\"shibing624/text2vec-base-chinese\")  # 中文效果更好\ndoc_embeddings = embedder.encode(knowledge_texts)\ndimension = doc_embeddings.shape[1]\nindex = faiss.IndexFlatL2(dimension)\nindex.add(np.array(doc_embeddings))\n\n# 问答函数\ndef answer_question_with_deepseek(question, top_k=2, max_new_tokens=200):\n    # 检索相关知识\n    q_embedding = embedder.encode([question])\n    distances, indices = index.search(np.array(q_embedding), top_k)\n    retrieved = [knowledge_texts[i] for i in indices[0]]\n\n    # 构造 Prompt\n    context = \"\\n\".join(retrieved)\n    prompt = f\"\"\"你是一位智能问答助手，请根据以下知识内容回答用户的问题。\n知识内容：\n{context}\n\n用户问题：{question}\n你的回答：\"\"\"\n\n    # 模型推理\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(llm.device)\n    with torch.no_grad():\n        outputs = llm.generate(\n            **inputs,\n            max_new_tokens=max_new_tokens,\n            do_sample=True,\n            temperature=0.7,\n            top_p=0.9,\n            repetition_penalty=1.1,\n        )\n    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n    # 去除prompt前缀，只返回回答部分\n    answer = response.split(\"你的回答：\")[-1].strip()\n    return answer\nquestion = \"向量数据库的作用是什么？\"\nprint(\"问：\", question)\nprint(\"答：\", answer_question_with_deepseek(question))\nquestion = \"什么是信息抽取？\"\nprint(\"问：\", question)\nprint(\"答：\", answer_question_with_deepseek(question))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T05:24:44.607466Z","iopub.execute_input":"2025-04-08T05:24:44.607787Z","iopub.status.idle":"2025-04-08T05:27:49.819150Z","shell.execute_reply.started":"2025-04-08T05:24:44.607762Z","shell.execute_reply":"2025-04-08T05:27:49.818394Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"cpp_kernels.py:   0%|          | 0.00/1.92k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76abd7ea32264d4fbe8da5a6b8cd690e"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/Qwen/Qwen-7B-Chat:\n- cpp_kernels.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"qwen_generation_utils.py:   0%|          | 0.00/14.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f1e88dc87764fdbb294ff0c0c67e67f"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/Qwen/Qwen-7B-Chat:\n- qwen_generation_utils.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\nA new version of the following files was downloaded from https://huggingface.co/Qwen/Qwen-7B-Chat:\n- cpp_kernels.py\n- qwen_generation_utils.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/19.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d38e21562074d2b81a93a8f30f1c3b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"654dd53c298c419e8028aef3db2ea070"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00008.safetensors:   0%|          | 0.00/1.96G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02ac44ef04e64087812a7a993626056d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00008.safetensors:   0%|          | 0.00/2.02G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c908614f50e40df94b61c879305009e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00008.safetensors:   0%|          | 0.00/2.02G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06389c0117f8495283fbaba885200d9e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00008.safetensors:   0%|          | 0.00/2.02G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"127073746ceb49adaa391938f8ede89c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00005-of-00008.safetensors:   0%|          | 0.00/2.02G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"643e3977ed484aa0bcbd992f00d87de8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00006-of-00008.safetensors:   0%|          | 0.00/2.02G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7eeafaf7fa404d96a69f21fb54f2bddd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00007-of-00008.safetensors:   0%|          | 0.00/2.02G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f02e976c17114a21a41823c15dd59258"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00008-of-00008.safetensors:   0%|          | 0.00/1.33G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be7ae5eb22f84a2bb2677d3a8eb32f19"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40941816e9624132ac79cd2bfb101c2e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/273 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b54e174d9dfc4eddb867b193b753ae18"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/230 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"041a1f4f2a1a49c5b3b58184a39a7c00"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/13.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c606836b440f47c1869f4cb131f33ec4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/54.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf96a2772e774496b1e76f490ad97fed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/856 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8eb5a1eb7b49441cb2382f08d9ab07e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/409M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b438d231f8d412c8160983b2ab1944e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/319 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0dc34d8ea6464c54a41d32ff03513bf0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/110k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d41322e8aab5497d9d8a0c96501fafca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9a6774c68284eb6b1ea6bd81a0d8697"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/74.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35b4266e95e940d5bf6786902280b326"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29be122f97784621b4771c6feed4e92e"}},"metadata":{}},{"name":"stdout","text":"问： 向量数据库的作用是什么？\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98c382b99e2344379822ac0eb47d26ce"}},"metadata":{}},{"name":"stdout","text":"答： 向量数据库是一种数据存储方式，它使用向量来表示文本，并且可以进行高效的语义搜索。这样，数据库可以在短时间内找到与查询语句最匹配的数据，从而提高查询效率。此外，向量数据库还可以用于其他自然语言处理任务，例如文本分类、情感分析等。\n问： 什么是信息抽取？\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"821864bc808549579417722794e50a4c"}},"metadata":{}},{"name":"stdout","text":"答： 信息抽取是从非结构化或半结构化数据中提取结构化信息的过程。\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nimport faiss\nimport numpy as np\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nimport torch\n\nmodel_name = \"01-ai/Yi-6B-Chat\"\ntokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\nllm = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n    trust_remote_code=True\n)\nllm.eval()\n\n\n# 知识库内容\nknowledge_texts = [\n    \"数据存储是指以一定结构保存数据的方式，包括关系型数据库和非关系型数据库。\",\n    \"信息抽取是从非结构化或半结构化数据中提取结构化信息的过程。\",\n    \"向量数据库使用向量表示文本，可用于高效的语义搜索。\",\n    \"知识问答系统分为基于检索的问答和基于生成的问答。\",\n    \"知识图谱是一种语义网络，表示实体及其之间的关系。\"\n]\n\nppt_file_path = '/kaggle/input/ppttxt/ppt.txt'\n\n# 加载并分句（可按段落或换行分割）\nwith open(ppt_file_path, 'r', encoding='utf-8') as f:\n    ppt_content = f.read()\n\n# 分割成知识段（你可以根据自己的格式调整，以下按“换行”分段）\nppt_knowledge_list = [line.strip() for line in ppt_content.split('\\n') if line.strip()]\n\n# 合并\nknowledge_texts.extend(ppt_knowledge_list)\n\n# 文本向量化 + FAISS 向量搜索\nembedder = SentenceTransformer(\"shibing624/text2vec-base-chinese\")  # 中文效果更好\ndoc_embeddings = embedder.encode(knowledge_texts)\ndimension = doc_embeddings.shape[1]\nindex = faiss.IndexFlatL2(dimension)\nindex.add(np.array(doc_embeddings))\n\n# 问答函数\ndef answer_question_with_deepseek(question, top_k=2, max_new_tokens=512):\n    # 检索相关知识\n    q_embedding = embedder.encode([question])\n    distances, indices = index.search(np.array(q_embedding), top_k)\n    retrieved = [knowledge_texts[i] for i in indices[0]]\n\n    # 构造 Prompt\n    context = \"\\n\".join(retrieved)\n    prompt = f\"\"\"你是一位智能问答助手，请根据以下知识内容回答用户的问题。\n知识内容：\n{context}\n\n用户问题：{question}\n你的回答：\"\"\"\n\n    # 模型推理\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(llm.device)\n    with torch.no_grad():\n        outputs = llm.generate(\n            **inputs,\n            max_new_tokens=max_new_tokens,\n            do_sample=True,\n            temperature=0.7,\n            top_p=0.9,\n            repetition_penalty=1.1,\n        )\n    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n    # 去除prompt前缀，只返回回答部分\n    answer = response.split(\"你的回答：\")[-1].strip()\n    return answer\nquestion = \"向量数据库的作用是什么？\"\nprint(\"问：\", question)\nprint(\"答：\", answer_question_with_deepseek(question))\nquestion = \"什么是信息抽取？\"\nprint(\"问：\", question)\nprint(\"答：\", answer_question_with_deepseek(question))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T05:49:18.988301Z","iopub.execute_input":"2025-04-08T05:49:18.988605Z","iopub.status.idle":"2025-04-08T05:52:40.294589Z","shell.execute_reply.started":"2025-04-08T05:49:18.988579Z","shell.execute_reply":"2025-04-08T05:52:40.293692Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2acb004eaf75450f93dbdc7dbfb589d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61507b96e16146bb9269e74dd14b2a3e"}},"metadata":{}},{"name":"stdout","text":"问： 向量数据库的作用是什么？\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80a9d2d68e1547e4ba0894a396efacae"}},"metadata":{}},{"name":"stdout","text":"答： 自然语言处理的许多应用都可以从向量数据库中受益，例如机器翻译、实体识别、情感分析、推荐系统和语音识别。在这些任务中，向量数据库可以帮助模型更好地理解文本的语义内容，从而提供更准确的结果。\n问： 什么是信息抽取？\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e05abe619384447aa6c43b558f857a03"}},"metadata":{}},{"name":"stdout","text":"答： 信息抽取是一种从各种数据源中提取有用的信息和知识的自动过程。它通常涉及到自然语言处理（NLP）和机器学习技术来理解和分析文本，以便识别和提取特定的实体、关系和概念。信息抽取可以用于构建数据库、支持决策制定以及进行知识发现等应用。\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"!pip install transformers_stream_generator","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T05:24:36.486536Z","iopub.execute_input":"2025-04-08T05:24:36.486842Z","iopub.status.idle":"2025-04-08T05:24:41.837107Z","shell.execute_reply.started":"2025-04-08T05:24:36.486819Z","shell.execute_reply":"2025-04-08T05:24:41.836218Z"}},"outputs":[{"name":"stdout","text":"Collecting transformers_stream_generator\n  Downloading transformers-stream-generator-0.0.5.tar.gz (13 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: transformers>=4.26.1 in /usr/local/lib/python3.10/dist-packages (from transformers_stream_generator) (4.47.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.1->transformers_stream_generator) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.1->transformers_stream_generator) (0.29.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.1->transformers_stream_generator) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.1->transformers_stream_generator) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.1->transformers_stream_generator) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.1->transformers_stream_generator) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.1->transformers_stream_generator) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.1->transformers_stream_generator) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.1->transformers_stream_generator) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.1->transformers_stream_generator) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers>=4.26.1->transformers_stream_generator) (2024.12.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers>=4.26.1->transformers_stream_generator) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers>=4.26.1->transformers_stream_generator) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers>=4.26.1->transformers_stream_generator) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers>=4.26.1->transformers_stream_generator) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers>=4.26.1->transformers_stream_generator) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers>=4.26.1->transformers_stream_generator) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers>=4.26.1->transformers_stream_generator) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.26.1->transformers_stream_generator) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.26.1->transformers_stream_generator) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.26.1->transformers_stream_generator) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.26.1->transformers_stream_generator) (2025.1.31)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers>=4.26.1->transformers_stream_generator) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers>=4.26.1->transformers_stream_generator) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers>=4.26.1->transformers_stream_generator) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers>=4.26.1->transformers_stream_generator) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers>=4.26.1->transformers_stream_generator) (2024.2.0)\nBuilding wheels for collected packages: transformers_stream_generator\n  Building wheel for transformers_stream_generator (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for transformers_stream_generator: filename=transformers_stream_generator-0.0.5-py3-none-any.whl size=12425 sha256=6efb90e4539ae51705fa58b06398f3f47d89b77fb396a067727b6180fd19b873\n  Stored in directory: /root/.cache/pip/wheels/95/4a/90/140f7b67d125906f6a165f38aad212ecb4a695ad0d87582437\nSuccessfully built transformers_stream_generator\nInstalling collected packages: transformers_stream_generator\nSuccessfully installed transformers_stream_generator-0.0.5\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!pip install bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T05:18:34.927798Z","iopub.execute_input":"2025-04-08T05:18:34.928089Z","iopub.status.idle":"2025-04-08T05:18:40.984618Z","shell.execute_reply.started":"2025-04-08T05:18:34.928068Z","shell.execute_reply":"2025-04-08T05:18:40.983697Z"}},"outputs":[{"name":"stdout","text":"Collecting bitsandbytes\n  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\nRequirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.1+cu121)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->bitsandbytes) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nDownloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.45.5\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!pip install transformers accelerate sentence-transformers faiss-cpu peft","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T01:40:07.905538Z","iopub.execute_input":"2025-04-07T01:40:07.905871Z","iopub.status.idle":"2025-04-07T01:40:14.598872Z","shell.execute_reply.started":"2025-04-07T01:40:07.905844Z","shell.execute_reply":"2025-04-07T01:40:14.597532Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.2.1)\nRequirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.3.1)\nCollecting faiss-cpu\n  Downloading faiss_cpu-1.10.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\nRequirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.14.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\nRequirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.0.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.12.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading faiss_cpu-1.10.0-cp310-cp310-manylinux_2_28_x86_64.whl (30.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hInstalling collected packages: faiss-cpu\nSuccessfully installed faiss-cpu-1.10.0\n","output_type":"stream"}],"execution_count":1}]}